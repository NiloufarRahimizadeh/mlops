{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ml_metadata"
      ],
      "metadata": {
        "id": "4lCUC6EL1kvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-data-validation"
      ],
      "metadata": {
        "id": "efs84S4x24uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ml_metadata.metadata_store import metadata_store\n",
        "from ml_metadata.proto import metadata_store_pb2\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TF version: {}'.format(tf.__version__))\n",
        "\n",
        "import tensorflow_data_validation as tfdv\n",
        "print('TFDV version: {}'.format(tfdv.version.__version__))\n",
        "\n",
        "import urllib\n",
        "import zipfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZduiqLIBcOT-",
        "outputId": "07e9aa03-6dd2-4315-8d42-be73393659df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.11.0\n",
            "TFDV version: 1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset"
      ],
      "metadata": {
        "id": "J4l5N-1rdwOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the zip file from GCP and unzip it\n",
        "url = 'https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/chicago_data.zip'\n",
        "zip, headers = urllib.request.urlretrieve(url)\n",
        "zipfile.ZipFile(zip).extractall()\n",
        "zipfile.ZipFile(zip).close()\n",
        "\n",
        "print(\"Here's what we downloaded:\")\n",
        "!ls -R data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFtPpvUPcXaU",
        "outputId": "d0e6c1bf-f040-4cc2-94dd-ad2660ef791d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's what we downloaded:\n",
            "data:\n",
            "eval  serving  train\n",
            "\n",
            "data/eval:\n",
            "data.csv\n",
            "\n",
            "data/serving:\n",
            "data.csv\n",
            "\n",
            "data/train:\n",
            "data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define ML Metadata's Storage Database"
      ],
      "metadata": {
        "id": "KWwpg3OzSB-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a connection config\n",
        "connection_config = metadata_store_pb2.ConnectionConfig()\n",
        "\n",
        "# Set an empty fake database proto\n",
        "connection_config.fake_database.SetInParent() \n",
        "\n",
        "# Setup the metadata store\n",
        "store = metadata_store.MetadataStore(connection_config)"
      ],
      "metadata": {
        "id": "8fE50J5QceS6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register ArtifactTypes"
      ],
      "metadata": {
        "id": "EGSzM5pnU-YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ArtifactType for the input dataset\n",
        "data_artifact_type = metadata_store_pb2.ArtifactType()\n",
        "data_artifact_type.name = 'DataSet'\n",
        "data_artifact_type.properties['name'] = metadata_store_pb2.STRING\n",
        "data_artifact_type.properties['split'] = metadata_store_pb2.STRING\n",
        "data_artifact_type.properties['version'] = metadata_store_pb2.INT\n",
        "\n",
        "# Register artifact type to the Metadata Store\n",
        "data_artifact_type_id = store.put_artifact_type(data_artifact_type)\n",
        "\n",
        "# Create ArtifactType for Schema\n",
        "schema_artifact_type = metadata_store_pb2.ArtifactType()\n",
        "schema_artifact_type.name = 'Schema'\n",
        "schema_artifact_type.properties['name'] = metadata_store_pb2.STRING\n",
        "schema_artifact_type.properties['version'] = metadata_store_pb2.INT\n",
        "\n",
        "# Register artifact type to the Metadata Store\n",
        "schema_artifact_type_id = store.put_artifact_type(schema_artifact_type)\n",
        "\n",
        "print('Data artifact type:\\n', data_artifact_type)\n",
        "print('Schema artifact type:\\n', schema_artifact_type)\n",
        "print('Data artifact type ID:', data_artifact_type_id)\n",
        "print('Schema artifact type ID:', schema_artifact_type_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3l38ng5U0c3",
        "outputId": "92fdb47b-72ca-4e8d-eacc-8cb5df10137d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data artifact type:\n",
            " name: \"DataSet\"\n",
            "properties {\n",
            "  key: \"name\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"split\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "\n",
            "Schema artifact type:\n",
            " name: \"Schema\"\n",
            "properties {\n",
            "  key: \"name\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "\n",
            "Data artifact type ID: 10\n",
            "Schema artifact type ID: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register ExecutionType"
      ],
      "metadata": {
        "id": "ll_zFXMDXNgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ExecutionType for Data Validation component\n",
        "dv_execution_type = metadata_store_pb2.ExecutionType()\n",
        "dv_execution_type.name = 'Data Validation'\n",
        "dv_execution_type.properties['state'] = metadata_store_pb2.STRING\n",
        "\n",
        "# Register execution type to the Metadata Store\n",
        "dv_execution_type_id = store.put_execution_type(dv_execution_type)\n",
        "\n",
        "print('Data validation execution type:\\n', dv_execution_type)\n",
        "print('Data validation execution type ID:', dv_execution_type_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1liIcZDXMv8",
        "outputId": "a2a8bf00-d8a3-4c1b-a2df-f792c11f4ae7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data validation execution type:\n",
            " name: \"Data Validation\"\n",
            "properties {\n",
            "  key: \"state\"\n",
            "  value: STRING\n",
            "}\n",
            "\n",
            "Data validation execution type ID: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate input artifact unit"
      ],
      "metadata": {
        "id": "msHJqqwWYc56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare input artifact of type DataSet\n",
        "data_artifact = metadata_store_pb2.Artifact()\n",
        "data_artifact.uri = './data/train/data.csv'\n",
        "data_artifact.type_id = data_artifact_type_id\n",
        "data_artifact.properties['name'].string_value = 'Chicago Taxi dataset'\n",
        "data_artifact.properties['split'].string_value = 'train'\n",
        "data_artifact.properties['version'].int_value = 1\n",
        "\n",
        "# Submit input artifact to the Metadata Store\n",
        "data_artifact_id = store.put_artifacts([data_artifact])[0]\n",
        "\n",
        "print('Data artifact:\\n', data_artifact)\n",
        "print('Data artifact ID:', data_artifact_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9LUruPzXJnM",
        "outputId": "1f36afc9-3a9e-4731-8ada-8c69b19ea84e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data artifact:\n",
            " type_id: 10\n",
            "uri: \"./data/train/data.csv\"\n",
            "properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"Chicago Taxi dataset\"\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split\"\n",
            "  value {\n",
            "    string_value: \"train\"\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value {\n",
            "    int_value: 1\n",
            "  }\n",
            "}\n",
            "\n",
            "Data artifact ID: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate execution unit"
      ],
      "metadata": {
        "id": "I6DdWMDBZwjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the Execution of a Data Validation run\n",
        "dv_execution = metadata_store_pb2.Execution()\n",
        "dv_execution.type_id = dv_execution_type_id\n",
        "dv_execution.properties['state'].string_value = 'RUNNING'\n",
        "\n",
        "# Submit execution unit to the Metadata Store\n",
        "dv_execution_id = store.put_executions([dv_execution])[0]\n",
        "\n",
        "print('Data validation execution:\\n', dv_execution)\n",
        "print('Data validation execution ID:', dv_execution_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMr_ZlpwXEf5",
        "outputId": "3c740edb-31da-46b9-de1a-99a50498e8f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data validation execution:\n",
            " type_id: 12\n",
            "properties {\n",
            "  key: \"state\"\n",
            "  value {\n",
            "    string_value: \"RUNNING\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Data validation execution ID: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register input event\n",
        "* An event defines a relationship between artifacts and executions. You will generate the input event relationship for dataset artifact and data validation execution units."
      ],
      "metadata": {
        "id": "7uFQ5NxEamGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare the input event\n",
        "input_event = metadata_store_pb2.Event()\n",
        "input_event.artifact_id = data_artifact_id\n",
        "input_event.execution_id = dv_execution_id\n",
        "input_event.type = metadata_store_pb2.Event.DECLARED_INPUT\n",
        "\n",
        "# Submit input event to the Metadata Store\n",
        "store.put_events([input_event])\n",
        "\n",
        "print('Input event:\\n', input_event)"
      ],
      "metadata": {
        "id": "HxmptwnbalfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8552b08-e8df-4878-d390-7c107c81469f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input event:\n",
            " artifact_id: 1\n",
            "execution_id: 1\n",
            "type: DECLARED_INPUT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the TFDV component\n",
        "* You will now run the TFDV component to generate the schema of dataset."
      ],
      "metadata": {
        "id": "WH1r8__g23Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = './data/train/data.csv'\n",
        "train_stats = tfdv.generate_statistics_from_csv(data_location=train_data)\n",
        "schema = tfdv.infer_schema(statistics=train_stats)\n",
        "\n",
        "schema_file = './schema.pbtxt'\n",
        "tfdv.write_schema_text(schema, schema_file)\n",
        "\n",
        "print(\"Dataset's Schema has been generated at:\", schema_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "s3g8VUTZ227v",
        "outputId": "7735c63a-4797-4f09-f2c4-6f25e389601a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_data_validation/utils/statistics_io_impl.py:91: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset's Schema has been generated at: ./schema.pbtxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate output artifact unit\n",
        "* Now that the TFDV component has finished running and schema has been generated, you can create the artifact for the generated schema."
      ],
      "metadata": {
        "id": "Kr-uWses4521"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema_artifact = metadata_store_pb2.Artifact()\n",
        "schema_artifact.uri = schema_file\n",
        "schema_artifact.type_id = schema_artifact_type_id\n",
        "schema_artifact.properties['version'].int_value = 1\n",
        "schema_artifact.properties['name'].string_value = 'Chicago Taxi Schema'\n",
        "\n",
        "# Submit output artifact to the Metadata Store\n",
        "schema_artifact_id = store.put_artifacts([schema_artifact])[0]\n",
        "\n",
        "print('Schema artifact:\\n', schema_artifact)\n",
        "print('Schema artifact ID:', schema_artifact_id)"
      ],
      "metadata": {
        "id": "KHoz0qfraZ-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a8f4fc-19c3-46dd-b3bd-fc0334f83e09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema artifact:\n",
            " type_id: 11\n",
            "uri: \"./schema.pbtxt\"\n",
            "properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"Chicago Taxi Schema\"\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value {\n",
            "    int_value: 1\n",
            "  }\n",
            "}\n",
            "\n",
            "Schema artifact ID: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register output event\n",
        "* Analogous to the input event earlier, you also want to define an output event to record the ouput artifact of a particular execution unit."
      ],
      "metadata": {
        "id": "jSq6-ZEa6EKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_event = metadata_store_pb2.Event()\n",
        "output_event.artifact_id = schema_artifact_id\n",
        "output_event.execution_id = dv_execution_id\n",
        "output_event.type = metadata_store_pb2.Event.DECLARED_OUTPUT\n",
        "\n",
        "# Submit output event to the Metadata Store\n",
        "store.put_events([output_event])\n",
        "\n",
        "print('Output event:\\n', output_event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv4Iu0Cz6DwY",
        "outputId": "dabc253c-7e3f-405e-83bb-f4525b2b06cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output event:\n",
            " artifact_id: 2\n",
            "execution_id: 1\n",
            "type: DECLARED_OUTPUT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update the execution unit\n",
        "* As the TFDV component has finished running successfully, you need to update the state of the execution unit and record it again to the store."
      ],
      "metadata": {
        "id": "cdxsrBte9VMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mark the `state` as `COMPLETED`\n",
        "dv_execution.id = dv_execution_id\n",
        "dv_execution.properties['state'].string_value = 'COMPLETED'\n",
        "\n",
        "# Update execution unit in the Metadata Store\n",
        "store.put_executions([dv_execution])\n",
        "\n",
        "print('Data validation execution:\\n', dv_execution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZnlmKmb57Z_",
        "outputId": "40f693ce-e713-4904-cca1-db6b7a43b2c5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data validation execution:\n",
            " id: 1\n",
            "type_id: 12\n",
            "properties {\n",
            "  key: \"state\"\n",
            "  value {\n",
            "    string_value: \"COMPLETED\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up Context Types and Generating a Context Unit\n",
        "* You can group the artifacts and execution units into a 'Context'. First, you need to define a 'ContextType' which defines the required context. It follows a similar format as artifact and event types."
      ],
      "metadata": {
        "id": "5TOGvSni-6f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ContextType\n",
        "expt_context_type = metadata_store_pb2.ContextType()\n",
        "expt_context_type.name = 'Experiment'\n",
        "expt_context_type.properties['note'] = metadata_store_pb2.STRING\n",
        "\n",
        "# Register context type to the Metadata Store\n",
        "expt_context_type_id = store.put_context_type(expt_context_type)"
      ],
      "metadata": {
        "id": "j70BzJq6-LYp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, you can create an instance of this context type"
      ],
      "metadata": {
        "id": "3mJvuLTu__W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the context\n",
        "expt_context = metadata_store_pb2.Context()\n",
        "expt_context.type_id = expt_context_type_id\n",
        "# Give the experiment a name\n",
        "expt_context.name = 'Demo'\n",
        "expt_context.properties['note'].string_value = 'Walkthrough of metadata'\n",
        "\n",
        "# Submit context to the Metadata Store\n",
        "expt_context_id = store.put_contexts([expt_context])[0]\n",
        "\n",
        "print('Experiment Context type:\\n', expt_context_type)\n",
        "print('Experiment Context type ID: ', expt_context_type_id)\n",
        "\n",
        "print('Experiment Context:\\n', expt_context)\n",
        "print('Experiment Context ID: ', expt_context_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmuAzp1A_-ft",
        "outputId": "25ecf155-fff9-4f7a-c9e3-2521ec173929"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment Context type:\n",
            " name: \"Experiment\"\n",
            "properties {\n",
            "  key: \"note\"\n",
            "  value: STRING\n",
            "}\n",
            "\n",
            "Experiment Context type ID:  13\n",
            "Experiment Context:\n",
            " type_id: 13\n",
            "name: \"Demo\"\n",
            "properties {\n",
            "  key: \"note\"\n",
            "  value {\n",
            "    string_value: \"Walkthrough of metadata\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Experiment Context ID:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate attribution and association relationships\n"
      ],
      "metadata": {
        "id": "CSIQgfWCAswo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNXgFBm1An3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}